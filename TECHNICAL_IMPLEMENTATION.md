# Техническая реализация проекта Ifarma BE Study Planner

## Обзор

Проект представляет собой AI-инструмент для автоматизированного планирования исследований биоэквивалентности (BE). Система принимает параметры лекарственного препарата, автоматически подбирает дизайн исследования, рассчитывает размер выборки, выполняет регуляторные проверки и генерирует синопсис протокола.

---

## Архитектура

Проект построен по модульной слоистой архитектуре. Каждый модуль отвечает за одну функциональную область и взаимодействует с остальными через доменные модели.

```
┌──────────────────────────────────────────────────────┐
│                  static/index.html                   │  ← UI (HTML-форма)
└──────────────────────┬───────────────────────────────┘
                       │ HTTP POST /design или /design-llm
┌──────────────────────▼───────────────────────────────┐
│                   api/main.py                        │  ← FastAPI-оркестратор
│   (координирует вызовы всех модулей)                 │
└──┬──────┬──────┬──────┬──────┬──────┬────────────────┘
   │      │      │      │      │      │
   ▼      ▼      ▼      ▼      ▼      ▼
models  pk_data design  stats   reg  synopsis/llm
```

### Поток данных

```
StudyInput (пользовательский ввод)
    │
    ▼
PKParameters ← pk_data/source.py (поиск в мини-БД)
    │
    ▼
StudyDesign ← design/logic.py (алгоритм выбора дизайна)
    │
    ▼
SampleSizeResult ← stats/sample_size.py (расчёт TOST)
    │
    ▼
List[RegulatoryIssue] ← reg/checks.py (7 проверок)
    │
    ├──→ synopsis/generator.py → Markdown (шаблонный путь)
    └──→ llm/client.py → GPT-4 → Markdown (LLM-путь)
    │
    ▼
DesignResponse / LLMDesignResponse (JSON-ответ клиенту)
```

---

## Модули и их техническая реализация

### 1. `models/domain.py` — Доменные модели

Используется **Pydantic v2** для валидации и сериализации данных. Все модели наследуют `BaseModel`.

| Модель | Назначение | Ключевые поля |
|--------|-----------|---------------|
| `StudyInput` | Входные параметры от пользователя | `inn`, `dose_mg`, `form`, `cv_intra`, `cv_category`, `regime`, `sex`, `bmi_min`/`bmi_max` |
| `PKParameters` | Фармакокинетические параметры препарата | `cmax`, `auc`, `tmax`, `t_half`, `cv_intra` |
| `StudyDesign` | Выбранный дизайн исследования | `name`, `type`, `periods`, `sequences`, `washout_days`, `rsabe_applicable` |
| `SampleSizeResult` | Результат расчёта выборки | `base_n`, `adjusted_for_dropout`, `dropout_rate`, `screen_fail_rate` |
| `RegulatoryIssue` | Регуляторное замечание | `code`, `severity` (info/warning/error), `message` |

Валидация обеспечивается Pydantic-аннотациями: `Field(gt=0)`, `Field(ge=0, le=1)`, `Literal[...]` для перечислений.

---

### 2. `pk_data/source.py` — Источник фармакокинетических данных

**Реализация:** Локальный словарь (`Dict[str, PKParameters]`) с PK-параметрами для 5 препаратов (каждый в русском и английском варианте МНН):

- омепразол / omeprazole
- метопролол / metoprolol
- амоксициллин / amoxicillin
- аторвастатин / atorvastatin
- диклофенак / diclofenac

**Алгоритм поиска:**
1. Нормализация МНН: `strip().lower()`
2. Поиск в словаре `HARDCODED_PK_DB`
3. Если не найден — возвращается пустой `PKParameters()` (все поля `None`)

> В продакшн-версии модуль может быть заменён на подключение к PubMed API, DrugBank или корпоративной БД.

---

### 3. `config.py` — Глобальная конфигурация

Хранит все числовые константы проекта:

| Параметр | Значение | Описание |
|----------|---------|----------|
| `DEFAULT_ALPHA` | 0.05 | Уровень значимости для TOST |
| `DEFAULT_POWER` | 0.80 | Статистическая мощность |
| `DEFAULT_DROPOUT_RATE` | 0.20 | Ожидаемая доля выбывших |
| `DEFAULT_SCREEN_FAIL_RATE` | 0.20 | Ожидаемая доля непрошедших скрининг |
| `BE_LOWER` / `BE_UPPER` | 0.80 / 1.25 | Границы биоэквивалентности (T/R) |
| `CV_THRESHOLD_REPLICATE_3WAY` | 0.30 | Порог CV для перехода на 2×3×3 |
| `CV_THRESHOLD_REPLICATE_4WAY` | 0.50 | Порог CV для перехода на 2×4 |
| `T_HALF_PARALLEL_THRESHOLD` | 48.0 ч | Порог T½ для параллельного дизайна |
| `MIN_WASHOUT_DAYS` | 7.0 дней | Минимальный wash-out |
| `DESIGN_ADJUSTMENT` | dict | Поправочные коэффициенты размера выборки |

Все модули импортируют константы непосредственно из `config`.

---

### 4. `design/logic.py` — Алгоритм выбора дизайна

#### Определение эффективного CVintra (`_effective_cv`)

Приоритет источников значения CV:
1. Числовое значение от пользователя (`study_input.cv_intra`)
2. Значение из PK-базы (`pk.cv_intra`)
3. Категория пользователя → значение по умолчанию (`low` → 0.25, `high` → 0.45)
4. Глобальное умолчание: 0.25

#### Расчёт wash-out (`_washout_days`)

```
wash_out = max(5 × T½ / 24, MIN_WASHOUT_DAYS)
```

Если T½ неизвестен, используется `MIN_WASHOUT_DAYS` (7 дней).

#### Правила выбора дизайна (`select_study_design`)

```
if T½ > 48 ч:
    → параллельный дизайн (1 период, wash-out = 0)
elif CVintra ≤ 0.30:
    → стандартный 2×2 перекрёстный (2 периода, последовательности TR/RT)
elif CVintra ≤ 0.50:
    → реплицированный 2×3×3 (3 периода, TRR/RRT, RSABE = да)
else:
    → реплицированный 2×4 (4 периода, TRTR/RTRT, RSABE = да)
```

Если пользователь указал `preferred_design`, название дизайна обновляется (расчётные параметры сохраняются).

---

### 5. `stats/sample_size.py` — Расчёт размера выборки

#### Математическая основа

Используется **нормальное приближение** для теста TOST (Two One-Sided Tests) на лог-трансформированных данных.

**Шаг 1.** Оценка дисперсии из CV:

```
σ² = ln(1 + CV²)
```

**Шаг 2.** Квантили нормального распределения — приближение Абрамовица–Стегуна (Abramowitz & Stegun 26.2.23):

```python
t = √(−2 · ln(p))
z = t − (c₀ + c₁t + c₂t²) / (1 + d₁t + d₂t² + d₃t³)
```

**Шаг 3.** Базовый N для 2×2 cross-over (на одну последовательность):

```
n_per_seq = ⌈2 · σ² · (z_{1−α} + z_{power})² / (ln(θ_upper))²⌉
```

Минимум 6 на группу. Общий `base_n = 2 × n_per_seq`.

**Шаг 4.** Поправка на тип дизайна:

| Дизайн | Множитель |
|--------|-----------|
| 2×2 | 1.0 |
| 2×3×3 | 1.1 |
| 2×4 | 1.2 |
| parallel | 1.3 |

**Шаг 5.** Поправка на потери (drop-out + screen-fail):

```
retention = (1 − dropout_rate) × (1 − screen_fail_rate)
adjusted_n = ⌈base_n / retention⌉
```

Результат округляется до чётного числа (для балансировки последовательностей).

---

### 6. `reg/checks.py` — Регуляторные проверки

Реализует 7 правил, основанных на Решении № 85 ЕАЭС и принципах GCP:

| # | Код | Уровень | Условие срабатывания |
|---|-----|---------|---------------------|
| 1 | `PERIODS_INCONSISTENT` | error | Тип дизайна предполагает ≥2 периодов, но указан 1 |
| 2 | `WASHOUT_TOO_SHORT` | warning | `washout_days < 5 × T½ / 24` |
| 3 | `LOW_SAMPLE_SIZE` | warning | `base_n < 12` |
| 4 | `FASTED_FED_SPLIT` | info | Режим «оба» при 2-периодном дизайне |
| 5 | `RSABE_MAY_BE_CONSIDERED` | info | CV > 0.30, но RSABE не отмечен |
| 6 | `HIGH_DROPOUT` | warning | Уровень drop-out > 30% |
| 7 | `LONG_WASHOUT` | info | Wash-out > 28 дней |

Модуль использует собственную копию `_effective_cv()` для определения CV.

---

### 7. `synopsis/` — Генерация синопсиса

#### `templates.py` — Текстовые шаблоны

Содержит предопределённые медицинские тексты на русском языке:
- **Критерии включения** (7 пунктов) — с плейсхолдерами `{min_age}`, `{max_age}`, `{bmi_min}`, `{bmi_max}`
- **Критерии исключения** (7 пунктов)
- **План мониторинга безопасности** — статический текст
- **Биоаналитический метод** — описание ВЭЖХ-МС/МС и валидации

#### `generator.py` — Сборка Markdown-документа

Функция `generate_synopsis_markdown()` собирает синопсис из 10 разделов:

1. Название протокола
2. Цели исследования
3. Задачи исследования (4 пункта)
4. Дизайн исследования (таблица параметров)
5. Популяция и критерии отбора (включение/исключение)
6. PK-параметры (таблица)
7. Статистическая методология (ANOVA, 90% ДИ, границы 80–125%)
8. План мониторинга безопасности
9. Биоаналитический метод
10. Расчёт размера выборки
11. Автоматические замечания (с иконками по уровню серьёзности)

Вспомогательные функции: `_regime_label()`, `_sex_label()`, `_severity_icon()` для локализации.

---

### 8. `llm/client.py` — LLM-интеграция

#### Генерация через GPT-4 (`generate_llm_synopsis`)

1. Проверка доступности библиотеки `openai`
2. Получение API-ключа (параметр или `OPENAI_API_KEY`)
3. Формирование промпта:
   - Системное сообщение: роль медицинского писателя
   - Пользовательское сообщение: `SYNOPSIS_GENERATION_PROMPT` + отформатированные данные исследования
4. Запрос к `client.chat.completions.create()` (temperature=0.7, max_tokens=4000)

#### Улучшение синопсиса (`enhance_synopsis_with_llm`)

Принимает шаблонный синопсис и отправляет его на «редактуру» через GPT-4. Полезно для улучшения стиля при сохранении технических данных.

#### Обработка ошибок

- `RuntimeError` — если `openai` не установлен
- `ValueError` — если API-ключ не найден
- `Exception` — при ошибках API (обёрнуто с описательным сообщением)

---

### 9. `api/main.py` — FastAPI-приложение

#### Эндпоинты

| Маршрут | Метод | Описание | Модель ответа |
|---------|-------|----------|---------------|
| `/` | GET | HTML-форма для ввода параметров | `HTMLResponse` |
| `/design` | POST | Шаблонная генерация синопсиса | `DesignResponse` |
| `/design-llm` | POST | LLM-генерация синопсиса | `LLMDesignResponse` |

#### Логика `/design`

```
StudyInput → get_pk_parameters → select_study_design →
calculate_sample_size → run_regulatory_checks → generate_synopsis_markdown → JSON
```

#### Логика `/design-llm`

Аналогична `/design`, но на этапе генерации синопсиса:
1. Если `LLM_ENABLED` и `OPENAI_API_KEY` установлен → вызывается `generate_llm_synopsis`
2. При ошибке и `LLM_FALLBACK_TO_TEMPLATE=True` → переключение на шаблонную генерацию
3. При ошибке и `LLM_FALLBACK_TO_TEMPLATE=False` → HTTP 500

Ответ `LLMDesignResponse` содержит дополнительные поля:
- `llm_generated: bool` — был ли синопсис создан через LLM
- `error_message: Optional[str]` — описание ошибки (если LLM не использовался)

---

### 10. `static/index.html` — Веб-интерфейс

**Технологии:** Чистый HTML5 + CSS3 + Vanilla JavaScript (без фреймворков).

**Структура формы** (3 карточки):
1. **Информация о препарате** — МНН, дозировка, форма, режим
2. **Вариабельность и дизайн** — CVintra, категория CV, тип исследования, предпочтительный дизайн, RSABE
3. **Параметры популяции** — возраст, пол, ИМТ

**Отправка:** `fetch('/design', { method: 'POST' })` с JSON-телом.

**Отображение результатов:**
- Таблица PK-параметров
- Таблица дизайна
- Таблица размера выборки
- Список замечаний с цветовой кодировкой (info/warning/error)
- Блок синопсиса с прокруткой

**Особенности:**
- CSS Grid для адаптивной вёрстки
- CSS-спиннер при загрузке
- Плавная прокрутка к результатам
- Медиа-запросы для мобильных устройств (≤640px)

---

## Стек технологий

| Компонент | Технология | Версия |
|-----------|-----------|--------|
| Язык | Python | 3.10+ |
| Валидация данных | Pydantic | ≥2.0, <3.0 |
| Веб-фреймворк | FastAPI | ≥0.100, <1.0 |
| ASGI-сервер | Uvicorn | ≥0.23, <1.0 |
| LLM-клиент | OpenAI Python SDK | ≥1.0.0, <2.0 |
| Фронтенд | HTML5/CSS3/JS | — |

---

## Запуск

```bash
# Установка зависимостей
pip install -r requirements.txt

# Запуск API-сервера
uvicorn api.main:app --reload
# Открыть: http://localhost:8000/

# Демо (шаблонная генерация)
python demo/example_workflow.py

# Демо (LLM-генерация, требуется OPENAI_API_KEY)
export OPENAI_API_KEY='ваш-ключ'
python demo/llm_demo.py
```

---

## Расширяемость

- **PK-данные:** Заменить `HARDCODED_PK_DB` на подключение к API или БД
- **Дизайн:** Добавить новые типы дизайнов в `select_study_design` и `DESIGN_ADJUSTMENT`
- **Регуляторные правила:** Добавить проверки в `run_regulatory_checks`
- **LLM-провайдеры:** Заменить клиент OpenAI на Anthropic, локальные модели и т.д.
- **Шаблоны:** Расширить `templates.py` для других языков или стандартов
